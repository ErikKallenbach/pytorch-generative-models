{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.makedirs('./images/wgan', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "random.seed(1234)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE  = 64\n",
    "N_EPOCHS = 100\n",
    "IMAGE_SIZE = 64\n",
    "LATENT_DIM = 100\n",
    "D_UPDATES = 5\n",
    "D_CLAMP = 0.01\n",
    "PRINT_EVERY = 5\n",
    "N_SHOW = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = datasets.CIFAR10('.data', \n",
    "                        train=True, \n",
    "                        download=True, \n",
    "                        transform=transforms,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = DataLoader(data,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      shuffle=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, image_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=latent_dim, \n",
    "                               out_channels=image_size*8, \n",
    "                               kernel_size=4,\n",
    "                               stride=1,\n",
    "                               padding=0,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(image_size*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=image_size*8, \n",
    "                               out_channels=image_size*4, \n",
    "                               kernel_size=4,\n",
    "                               stride=2,\n",
    "                               padding=1,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(image_size*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=image_size*4, \n",
    "                               out_channels=image_size*2, \n",
    "                               kernel_size=4,\n",
    "                               stride=2,\n",
    "                               padding=1,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(image_size*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=image_size*2, \n",
    "                               out_channels=image_size, \n",
    "                               kernel_size=4,\n",
    "                               stride=2,\n",
    "                               padding=1,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(image_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=image_size, \n",
    "                               out_channels=3, \n",
    "                               kernel_size=4,\n",
    "                               stride=2,\n",
    "                               padding=1,\n",
    "                               bias=False),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "        \n",
    "            nn.Conv2d(in_channels=3,\n",
    "                      out_channels=image_size,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=image_size,\n",
    "                      out_channels=image_size*2,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(image_size*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=image_size*2,\n",
    "                      out_channels=image_size*4,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(image_size*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=image_size*4,\n",
    "                      out_channels=image_size*8,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(image_size*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=image_size*8,\n",
    "                      out_channels=1,\n",
    "                      kernel_size=4,\n",
    "                      stride=1,\n",
    "                      padding=0,\n",
    "                      bias=False),\n",
    "            \n",
    "            #no sigmoid!\n",
    "            #nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(LATENT_DIM, IMAGE_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(IMAGE_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't use BCE loss!\n",
    "#criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now use RMSprop instead of Adam, with lr of 0.00005\n",
    "G_optimizer = optim.RMSprop(G.parameters(), lr=0.00005)\n",
    "D_optimizer = optim.RMSprop(D.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels\n",
    "real_labels = torch.ones(BATCH_SIZE,).to(device)\n",
    "fake_labels = torch.zeros(BATCH_SIZE,).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, N_EPOCHS+1):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for _ in range(len(iterator)):\n",
    "                \n",
    "        #=====================#\n",
    "        # TRAIN DISCRIMINATOR #\n",
    "        #=====================#\n",
    "            \n",
    "        #do multiple D updates for every G update\n",
    "        for _ in range(D_UPDATES): \n",
    "        \n",
    "            #zero discriminator gradients\n",
    "            D.zero_grad()\n",
    "\n",
    "            #get batch of real images\n",
    "            x, _ = next(iter(iterator))\n",
    "\n",
    "            #place images on GPU \n",
    "            x = x.to(device)\n",
    "\n",
    "            #sample noise\n",
    "            z = torch.randn(x.shape[0], LATENT_DIM, 1, 1).to(device)\n",
    "\n",
    "            #generate images\n",
    "            with torch.no_grad():\n",
    "                generated_images = G(z)\n",
    "\n",
    "            #put real images through discriminator\n",
    "            pred_real = D(x)\n",
    "\n",
    "            #put fake images through the discriminator\n",
    "            #need to detach so don't backpropagate through generator\n",
    "            pred_fake = D(generated_images.detach())\n",
    "\n",
    "            #discriminator error is G(D(z)) - D(x)\n",
    "            D_error = pred_fake.mean() - pred_real.mean()\n",
    "\n",
    "            #backpropagate errors to get gradients\n",
    "            D_error.backward()\n",
    "\n",
    "            #use gradient to update discriminator parameters\n",
    "            D_optimizer.step()\n",
    "        \n",
    "            #clamp D parameters\n",
    "            for p in D.parameters():\n",
    "                p.data.clamp_(-D_CLAMP, +D_CLAMP)\n",
    "        \n",
    "        #=================#\n",
    "        # TRAIN GENERATOR #\n",
    "        #=================#\n",
    "        \n",
    "        #zero generator gradients\n",
    "        G.zero_grad()\n",
    "        \n",
    "        #get batch of real images\n",
    "        x, _ = next(iter(iterator))\n",
    "        \n",
    "        #place images on GPU \n",
    "        x = x.to(device)\n",
    "        \n",
    "        #sample noise\n",
    "        z = torch.randn(x.shape[0], LATENT_DIM, 1, 1).to(device)\n",
    "        \n",
    "        #generate images\n",
    "        generated_images = G(z)\n",
    "        \n",
    "        #put fake images through the discriminator\n",
    "        pred_fake = D(generated_images)\n",
    "        \n",
    "        #generator error is negative of D(G(z))\n",
    "        G_error = -pred_fake.mean()\n",
    "        \n",
    "        #backpropagate errors to get gradients\n",
    "        G_error.backward()\n",
    "        \n",
    "        #use gradient to update generator parameters\n",
    "        G_optimizer.step()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if (epoch % PRINT_EVERY) == 0:\n",
    "    \n",
    "        #sample noise\n",
    "        z = torch.randn(N_SHOW*N_SHOW, LATENT_DIM, 1, 1).to(device)\n",
    "    \n",
    "        #generate images\n",
    "        with torch.no_grad():\n",
    "            generated_images = G(z)\n",
    "    \n",
    "        print(f'| Epoch: {epoch:03} | D_error: {D_error.item():.03f} | G_error: {G_error.item():.03f} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "\n",
    "        #display N_SHOW images\n",
    "        torchvision.utils.save_image(generated_images, \n",
    "                                     f'images/wgan/epoch{epoch:03}.png', \n",
    "                                     nrow=N_SHOW,\n",
    "                                     normalize=True)\n",
    "        \n",
    "        #display images\n",
    "        img = plt.imread(f'images/wgan/epoch{epoch:03}.png')\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
